name: Crawl Option Prices

# Runs every 15 minutes during trading hours (Mon-Fri)
on:
  schedule:
    # 8-17 UTC = 9-18 CET during winter, 10-19 CEST during summer
    - cron: "*/15 8-16 * * 1-5"

  workflow_dispatch:  # manual trigger

concurrency:
  group: crawl-options
  cancel-in-progress: false

jobs:
  crawl-prices:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy pytz psycopg2-binary python-dotenv playwright requests urllib3
          playwright install chromium
          echo "=== Installed packages ==="
          pip list | grep -i psycopg

      - name: Run price crawler
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_ANON_KEY: ${{ secrets.SUPABASE_ANON_KEY }}
        working-directory: "eurex price crawler"
        run: |
          echo "=== Python path ==="
          which python
          echo "=== Checking psycopg2 ==="
          python -c "import psycopg2; print('psycopg2 OK')"
          echo "=== Running crawler ==="
          python run_with_lock.py

      - name: Upload log on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: price-crawler-log-${{ github.run_id }}
          path: "eurex price crawler/*.log"
          if-no-files-found: ignore
